---
title: "Foundations of Probability and Statistics: Project Report"
author: "Dario Bertazioli, Andrea Corvaglia"
date: "17 agosto 2019"
geometry: margin=2cm
output:
  pdf_document:
    fig_height: 3
    fig_width: 5
    toc: yes
  html_document:
    fig_height: 3
    fig_width: 5
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, fig.align="center")
```

# Descriptive analysis on Y
\small
```{r}
data<- data1 <- read.csv("../data/Laptop2.csv")
str(data)
head(data,3)
```

```{r}
summary(data)
```

```{r}
nums <- sapply(data, is.numeric)
var_numeric <- data[,nums] 
head(var_numeric)
```

```{r}
sapply(data, function(x)(sum(is.na(x)))) # Non ci sono missing data!
```

```{r, fig.height=3.5, fig.width=10}
plot(data$Aggregated_Company,data$Price)
```

```{r}
library(ggplot2)
ggplot(data,aes(x = Price)) + geom_histogram(aes(y =..density..), bins= 25, fill = "grey",color ="black") +
        geom_vline(xintercept = quantile(data$Price, 0.50), color = "dark red", lty = 2) +geom_vline(xintercept = mean(data$Price), color = "dark blue", lty = 2) +
        labs(x = "Price", y ="Density") + ggtitle("Price Distribution with mean and median") +geom_density()
```

Quite skewed to the right, mean > median: we could try to apply a correction like Log(Y)

```{r}
ggplot(data,aes(x = log(Price))) + geom_histogram(aes(y =..density..),bins= 25, fill = "grey", color ="black") + 
  geom_vline(xintercept = quantile(log(data$Price), 0.50), color = "dark red", lty = 2) + geom_vline(xintercept = mean(log(data$Price)), color = "dark blue", lty = 2) +
  labs(x = "log(Price)", y ="Density") +ggtitle("log(Price) Distribution with mean and median")+  geom_density()
```

Now the distribution is looking a bit better (as regards normality)

```{r}
ggplot(data,aes(x = Price)) + geom_histogram(aes(y =..density..), bins= 25, fill = "grey", color ="black") +
  geom_vline(xintercept = mean(data$Price), color = "dark red") + geom_vline(xintercept = mean(data$Price) + sd(data$Price), color = "dark red", lty = 2) +
  geom_vline(xintercept = mean(data$Price) - sd(data$Price), color = "dark red", lty = 2) +labs(x = "Price", y ="Density") + ggtitle("Price Distribution (mean +/- sd)") + geom_density()

ggplot(data,aes(x = log(Price))) +geom_histogram(aes(y =..density..), bins= 25,fill = "grey",color ="black") +
  geom_vline(xintercept = mean(log(data$Price)), color = "dark red") + geom_vline(xintercept = mean(log(data$Price)) + sd(log(data$Price)), color = "dark red", lty = 2) +
  geom_vline(xintercept = mean(log(data$Price)) - sd(log(data$Price)), color = "dark red", lty = 2) + labs(x = "log(Price)", y ="Density") + ggtitle("log(Price) Distribution (mean +/- sd)") + geom_density()
```

```{r}
ggplot(data,aes(x = Price)) + geom_histogram(aes(y =..density..), bins= 25, fill = "grey", color ="black") + 
  geom_vline(xintercept = quantile(data$Price, 0.25), color = "dark red",lty = 2) + geom_vline(xintercept = quantile(data$Price, 0.5), color = "dark red", ) +
  geom_vline(xintercept = quantile(data$Price, 0.75), color = "dark red", lty = 2) + labs(x = "Price", y ="Density") + ggtitle("Price Distribution (quartiles)") + geom_density()

ggplot(data,aes(x = log(Price))) + geom_histogram(aes(y =..density..), bins= 25, fill = "grey", color ="black") +
  geom_vline(xintercept = quantile(log(data$Price), 0.25), color = "dark red",lty = 2) + geom_vline(xintercept = quantile(log(data$Price), 0.5), color = "dark red", ) +
  geom_vline(xintercept = quantile(log(data$Price), 0.75), color = "dark red", lty = 2) + labs(x = "log(Price)", y ="Density") + ggtitle("log(Price) Distribution (quartiles)") + geom_density()
```



Descrittive variabile dipendente price

```{r}
ggplot(data, aes(x = Price, fill = TypeName)) + geom_density(size = 0.6, alpha = .3) + labs(x = "Price", y ="Density", fill = "TypeName") + ggtitle("Price Density Distribution For TypeName") 

ggplot(data, aes(x = log(Price), fill = TypeName)) + geom_density(size = 0.6, alpha = .3) +labs(x = "log(Price)", y ="Density", fill = "TypeName") + ggtitle("log(Price) Density Distribution For TypeName") 

ggplot(data, aes(x = Price, fill = SolidStateDisk)) + geom_density(size = 0.6, alpha = .3) +labs(x = "Price", y ="Density", fill = "SolidStateDisk") + ggtitle("Price Density Distribution For SolidStateDisk") 

ggplot(data, aes(x = log(Price), fill = SolidStateDisk)) + geom_density(size = 0.6, alpha = .3) + labs(x = "log(Price)", y ="Density", fill = "SolidStateDisk") + ggtitle("log(Price) Density Distribution For SolidStateDisk") 
```

```{r}
library(psych)
describe(data$Price)
describe(log(data$Price))

library(nortest) # test per ipotesi di normalità
boxplot(data$Price, horizontal = T, ylab = c("Price") )
qqnorm(data$Price);qqline(data$Price)
shapiro.test(data$Price)
ad.test(data$Price)
```

Trying with the log correction:

```{r}
# Correzione NORMALITA'
library(nortest)
boxplot(log(data$Price), ylab="log(Price)", horizontal = T)
qqnorm(log(data$Price));qqline(log(data$Price))
shapiro.test(log(data$Price)) #better than before, but still not normal according to shapiro

ad.test(log(data$Price))
```

# Test on a mean (justify H0) on Y and confidence limits.

T-test

```{r}
# One sample

ref <-666 #prezzo medio di mercato pc 2019 (€)


t.test(log(data$Price),mu=log(ref),alternative = "greater")

# Wilcoxon Signed Rank Test
wilcox.test(log(data$Price), mu=log(ref), conf.int = TRUE)
```

# Test two means, two variances (Y vs X) .

```{r}
#Two sample
Razer<-data$Price[data$Company=="Razer"]
Other <-data$Price[data$Company!="Apple"]
t.test(log(Razer),log(Other),alternative = "greater")
wilcox.test(log(Razer), log(Other), alternative = "g")
# F test sulla varianza
var.test(log(Razer), log(Other), alternative = "two.sided")
```


# Association/chi square among some couples of categorical Xj


Variabili qualitative: tabella di contingenza e chi quadro
```{r}
b<-data
b.table<-table(b$SolidStateDisk,b$TypeName)
b.table
prop.table(b.table,2)
# chi square test 

chisq.test(b.table)

chi=chisq.test(b.table)
chi_norm=chi$statistic/(nrow(b)*min(nrow(b.table)-1,ncol(b.table)-1))
chi_norm

#Proviamo SolidStateDisk vs dedicated_GPU
b<-data
b.table<-table(b$SolidStateDisk,b$dedicated_GPU)
b.table
prop.table(b.table,2)
# chi square test 
chisq.test(b.table)

chi=chisq.test(b.table)
chi_norm=chi$statistic/(nrow(b)*min(nrow(b.table)-1,ncol(b.table)-1))
chi_norm
```


Correlazione per variabili quantitative
```{r}
# seleziona solo variabili quantitative
nums <- sapply(data, is.numeric)
var_numeric <- data[,nums] 
var_numeric$X=NULL
```

```{r}
# Test di correlazione. (Spearman's o Kendall tau)
#if(!require(corrgram)) install.packages("corrgram")
library(corrgram)
corrgram(var_numeric)

# Correlazione come grafo
library(qgraph)
detcor=cor(as.matrix(var_numeric), method="pearson")
round(detcor, 2)
# plot corr matrix: green positive red negative 
qgraph(detcor, shape="circle", posCol="darkgreen", negCol="darkred")

cor.test(var_numeric$Inches, var_numeric$Weight)
```

Boxplot di confronto (pre-anova)

```{r, fig.width=10}
boxplot(log(data$Price)~data$Aggregated_Company, main="Boxplot Prezzo per compagnia", col= rainbow(6), horizontal = F)
```


```{r}
boxplot(log(data$Price)~data$SolidStateDisk, main="Prezzo vs ssd", col= rainbow(2), horizontal = F)
```

# Anova one way Y = Xj, for a categorical X
```{r, fig.height=4, fig.width=6}
library(lsmeans)
lmC = lm(Price ~ TypeName, data=data)
summary(lmC)
drop1(lmC, test = 'F')

ls_TypeName = lsmeans(lmC,pairwise ~ TypeName,adjust = 'tukey')
ls_TypeName$lsmeans
plot(ls_TypeName$lsmeans, alpha = .05)
ls_TypeName$contrasts 


library(coefplot)
#library(forestmodel)
coefplot(lmC, intercept = FALSE)

par(mfrow = c(2,2))
plot(lmC)

#(not) normal distribution of residuals
par(mfrow=c(1,2))
boxplot(lmC$residuals, ylab="residuals (Price ~ Typename)")
qqnorm(lmC$residuals);qqline(lmC$residuals)

ad.test(lmC$residuals)
shapiro.test(lmC$residuals)

#let's try again with the log correction
lmC_log = lm(log(Price) ~ TypeName, data=data)
summary(lmC_log)#R^2 increases
drop1(lmC_log, test = 'F')

ls_TypeName_log = lsmeans(lmC_log,pairwise ~ TypeName,adjust = 'tukey')
ls_TypeName_log$lsmeans
plot(ls_TypeName_log$lsmeans, alpha = .05)
ls_TypeName_log$contrasts 


c= contrast(ls_TypeName_log , method = "eff") # contrast among predicted lsmeans and overall lsmean
c

coefplot(lmC_log, intercept = FALSE)

par(mfrow = c(2,2))
plot(lmC_log)

#(not) normal distribution of residuals
par(mfrow=c(1,2))
boxplot(lmC_log$residuals, ylab="residuals (logPrice ~ Typename)")
qqnorm(lmC_log$residuals);qqline(lmC_log$residuals)

ad.test(lmC_log$residuals) #normal now!
shapiro.test(lmC_log$residuals) #borderline now!
```

# Anova two way Y = Xj Xk for some categorical X

A due vie
```{r}
lmC = lm(log(Price) ~ SolidStateDisk*TypeName  , data=data)
summary(lmC)
drop1(lmC, test="F")

library(coefplot)
coefplot(lmC, intercept=FALSE)
interaction.plot(x.factor = data$TypeName, trace.factor = data$SolidStateDisk, response = log(data$Price), fun=mean, type="b", legend=TRUE, xlab = "Type", ylab="log(Price)", pch=c(1,1), col=c(2,5), main="Interaction Plot")
```

Regressione lineare
```{r}
lmA1<-lm(log(Price) ~ Frequenza  , data=data)
summary(lmA1)
plot(data$Frequenza,log(data$Price))
abline(lmA1,col="red")

lmA2<-lm(log(Price) ~ Frequenza+Pixel+Ram  , data=data)
summary(lmA2)
coefplot(lmA2, intercept=FALSE)
```

# Ancova Y = all covariates (qualitative +quantitative)

```{r}
lmK = lm(log(Price) ~ Aggregated_Company+TypeName+SolidStateDisk+ Frequenza+Pixel+Ram  , data=data)
```

```{r}
summary(lmK)
```

```{r}
drop1(lmK, .~., test="F")

ls=lsmeans(lmK,pairwise ~ Aggregated_Company ,adjust="tukey")
c= contrast(ls, method = "eff")
c
```

```{r, fig.height=4, fig.width=6}
data$Product=NULL
data$X=NULL
data$Company=NULL #uso solo Aggregated_Company
data$Gpu=NULL #uso solo Gpu_company
data$dedicated_GPU=NULL
data$ScreenResolution=NULL #uso solo Pixels
data$Risoluzione=NULL #uso solo Pixels
data$Cpu=NULL #uso solo Frequenza
data$Memory=NULL #uso solo MemorySSD, TotalMemory e SolidStateDisk

lm_full = lm(log(Price) ~ ., data = data)
summary(lm_full)
anova(lm_full, test="F")
drop1(lm_full, test="F")

coefplot(lm_full, intercept=FALSE) 

par(mfrow=c(2,2))
plot(lm_full)

par(mfrow=c(1,1))
par(mfrow=c(1,2))
boxplot(lm_full$residuals, ylab="residuals (log(Price) ~ .)")
qqnorm(lm_full$residuals);qqline(lm_full$residuals)

#normality tests
ad.test(lm_full$residuals)
shapiro.test(lm_full$residuals)
```
# APPENDIX

A look over outliers

```{r, fig.height=4, fig.width=6}
cooksd <- cooks.distance(lm_full) #Cook's Distance
cooksda=data.frame(cooksd)
summary(cooksd)

cutoff <- 4/((nrow(data)-length(lm_full$coefficients)-2)) # identify D values > 4/(n-k-1)
plot(lm_full, which=4, cook.levels=cutoff)# Cook's D plot

plot(cooksd, pch="*", cex=1, main="Influential Obs by Cooks distance") # plot cook's distance
abline(h = cutoff, col="red") # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red")#add labels

#extract influencial obs
influential <- as.numeric(names(cooksd)[(cooksd > cutoff)]) # influential row numbers
influ=data.frame(data[cooksd > cutoff, ])
filtered_data <- data[ !(row.names(data) %in% c(influential)), ]
dim(influ); dim(data); dim(filtered_data)

#removed outliers
lm_full_t_no_OUTliers = lm(log(Price) ~ ., data = filtered_data)
summary(lm_full_t_no_OUTliers)
par(mfrow=c(2,2))
plot(lm_full_t_no_OUTliers)
library(car)
ncvTest(lm_full_t_no_OUTliers)
```


```{r}
null = lm(log(Price) ~ 1, data = filtered_data)
full = lm(log(Price) ~ ., data = filtered_data)
library(MASS)
lm_fit = stepAIC(null, scope = list(upper = full), direction = "both", trace = FALSE)
summary(lm_fit)
drop1(lm_fit, test = 'F')
```



no log model and a log justification
```{r, fig.height=4, fig.width=6}
lm_full_no_log = lm(Price ~ ., data = data1)
#summary(lm_full_no_log)
par(mfrow=c(2,2))
plot(lm_full_no_log) 

ad.test(lm_full_no_log$residuals) 
shapiro.test(lm_full_no_log$residuals)  


library(MASS)
boxcoxreg1<-boxcox(lm_full_no_log, plotit=T) #to justify log correction

#lambda=boxcoxreg1$x[which.max(boxcoxreg1$y)]
#lambda #not exactly lambda= 0 but compatible, one could also apply y'=((y^lambda) - 1) / lambda
```
