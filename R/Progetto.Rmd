---
title: "Progetto"
author: "Andrea Corvaglia"
date: "17 agosto 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## TO DO:

>La Gpu con 112 livelli � inutilizzabile, possiamo dividere in integrata e dedicata, oppure dividere per le marche.

>> @Dario: Per la gpu farei innanzitutto una divisione tra integrata e dedicata, e tra quelle dedicate le suddividerei per VRAM (inizialmente pensavo di cercare dei prezzi per avere una stima quantitativa di quanto valga la gpu dedicata, però bisognerebbe cercare prezzi medi e visto che i modelli son tanti mi pare troppo lavoro e non chissà quanto significativo)


>Anche la memoria � problematica, ho gi� estratto la presenza o meno dell'SSD, ma bisogna pensare ad un modo di valutare la memoria.

>> @Dario: ottimo la divisione SSD/HD, per avere un indicazione quantitativa potremmo cercare il prezzo di un gb di SSD e di un gb di HD da una fonte affidabile, e pesare l'importanza delle dimensioni su questo indicatore, che ne dite?



```{r}
data <- read.csv("../data/Laptop2.csv")
str(data)
head(data)
```

```{r}
summary(data)
```

```{r}
nums <- sapply(data, is.numeric)
var_numeric <- data[,nums] 
head(var_numeric)
```
```{r}
data$Weight<-as.numeric(data$Weight)
data$Ram<-as.numeric(data$Ram)
```

```{r}
sapply(data, function(x)(sum(is.na(x))))
# Non ci sono missing data!
```

```{r}
plot(data$Company,data$Price)
```

```{r}
class(data$Ram)
plot(density(data$Frequenza))

#hist(data$Price, breaks=25, probability=TRUE)
#lines(density(data$Price))
```


```{r}
library(ggplot2)
ggplot(data,aes(x = Price)) + 
        geom_histogram(aes(y =..density..),
                       bins= 25,
                       fill = "grey",
                       color ="black") +
        geom_vline(xintercept = quantile(data$Price, 0.50), color = "dark red", lty = 2) +
        geom_vline(xintercept = mean(data$Price), color = "dark blue", lty = 2) +
        labs(x = "Price", y ="Density") +
        ggtitle("Price Distribution with mean and median") +
          geom_density()

```

Quite skewed to the right, mean > media

We could try to apply a correction like Log(Y)

```{r}

data$LogPrice=log(data$Price)
ggplot(data,aes(x = log(Price))) + 
        geom_histogram(aes(y =..density..),
                       bins= 25,
                       fill = "grey",
                       color ="black") +
        geom_vline(xintercept = quantile(data$LogPrice, 0.50), color = "dark red", lty = 2) +
        geom_vline(xintercept = mean(data$LogPrice), color = "dark blue", lty = 2) +
        labs(x = "log(Price)", y ="Density") +
        ggtitle("log(Price) Distribution with mean and median")+  geom_density()
```

Now the distribution is looking a bit better (as regards normality)

```{r}
ggplot(data,aes(x = Price)) + 
        geom_histogram(aes(y =..density..),
                       bins= 25,
                       fill = "grey",
                       color ="black") +
        geom_vline(xintercept = mean(data$Price), color = "dark red") +
        geom_vline(xintercept = mean(data$Price) + sd(data$Price), color = "dark red", lty = 2) +
        geom_vline(xintercept = mean(data$Price) - sd(data$Price), color = "dark red", lty = 2) +
        labs(x = "Price", y ="Density") +
        ggtitle("Price Distribution (mean +/- sd)") +
          geom_density()

```{r}
ggplot(data,aes(x = log(Price))) + 
        geom_histogram(aes(y =..density..),
                       bins= 25,
                       fill = "grey",
                       color ="black") +
        geom_vline(xintercept = mean(data$LogPrice), color = "dark red") +
        geom_vline(xintercept = mean(data$LogPrice) + sd(data$LogPrice), color = "dark red", lty = 2) +
        geom_vline(xintercept = mean(data$LogPrice) - sd(data$LogPrice), color = "dark red", lty = 2) +
        labs(x = "log(Price)", y ="Density") +
        ggtitle("log(Price) Distribution (mean +/- sd)") +
          geom_density()

```


```{r}
ggplot(data,aes(x = Price)) + 
        geom_histogram(aes(y =..density..),
                       bins= 25,
                       fill = "grey",
                       color ="black") +
        geom_vline(xintercept = quantile(data$Price, 0.25), color = "dark red",lty = 2) +
        geom_vline(xintercept = quantile(data$Price, 0.5), color = "dark red", ) +
        geom_vline(xintercept = quantile(data$Price, 0.75), color = "dark red", lty = 2) +
        labs(x = "Price", y ="Density") +
        ggtitle("Price Distribution (quartiles)") +
          geom_density()

ggplot(data,aes(x = log(Price))) + 
        geom_histogram(aes(y =..density..),
                       bins= 25,
                       fill = "grey",
                       color ="black") +
        geom_vline(xintercept = quantile(data$LogPrice, 0.25), color = "dark red",lty = 2) +
        geom_vline(xintercept = quantile(data$LogPrice, 0.5), color = "dark red", ) +
        geom_vline(xintercept = quantile(data$LogPrice, 0.75), color = "dark red", lty = 2) +
           labs(x = "log(Price)", y ="Density") +
        ggtitle("log(Price) Distribution (quartiles)") +
          geom_density()
```



Descrittive variabile dipendente price

```{r}
ggplot(data, aes(x = Price, fill = TypeName)) + 
        geom_density(size = 0.6, alpha = .3) +
        labs(x = "Price", y ="Density", fill = "TypeName") +
        ggtitle("Price Density Distribution For TypeName") 

ggplot(data, aes(x = log(Price), fill = TypeName)) + 
        geom_density(size = 0.6, alpha = .3) +
        labs(x = "log(Price)", y ="Density", fill = "TypeName") +
        ggtitle("log(Price) Density Distribution For TypeName") 

ggplot(data, aes(x = Price, fill = SolidStateDisk)) + 
        geom_density(size = 0.6, alpha = .3) +
        labs(x = "Price", y ="Density", fill = "SolidStateDisk") +
        ggtitle("Price Density Distribution For SolidStateDisk") 

ggplot(data, aes(x = log(Price), fill = SolidStateDisk)) + 
        geom_density(size = 0.6, alpha = .3) +
        labs(x = "log(Price)", y ="Density", fill = "SolidStateDisk") +
        ggtitle("log(Price) Density Distribution For SolidStateDisk") 

```

```{r}
library(psych)
describe(data$Price)

# NORMALITA'

boxplot(data$Price)
qqnorm(data$Price);qqline(data$Price)
shapiro.test(data$Price)
ad.test(data$Price)

#wilcox.test(data$Price, conf.int = TRUE, mu = ) #worth it?
if(!require(Envstats)) install.packages("EnvStats")
library(EnvStats)

VarTest(sample(data$Price), sigma.squared = (sd(data$Price)*sd(data$Price)))
```

Trying with the log correction:

```{r}
# Correzione NORMALITA'
library(nortest)
boxplot(data$LogPrice)
qqnorm(data$LogPrice);qqline(data$LogPrice)
shapiro.test(data$LogPrice) #better than before, but still not normal according to shapiro

ad.test(data$LogPrice)
```


T-test

```{r}
# One sample
ref <- mean(data$Price)
Apple<-data$Price[data$Company=="Apple"]
t.test(Apple,mu=ref,alternative = "greater")
# Wilcoxon Signed Rank Test
wilcox.test(Apple, mu=ref, conf.int = TRUE)
#Two sample
Other <-data$Price[data$Company!="Apple"]
wilcox.test(Apple, Other, alternative = "g")
# F test sulla varianza
var.test(Apple, Other, alternative = "two.sided")
```





Variabili qualitative: tabella di contingenza e chi quadro
```{r}
b<-data
b.table<-table(b$SolidStateDisk,b$TypeName)
b.table
prop.table(b.table,2)
# chi square test 

chisq.test(b.table)

chi=chisq.test(b.table)
chi_norm=chi$statistic/(nrow(b)*min(nrow(b.table)-1,ncol(b.table)-1))
chi_norm

summary(b.table)

```


Correlazione per variabili quantitative

```{r}
# seleziona solo variabili quantitative
nums <- sapply(data, is.numeric)
var_numeric <- data[,nums] 
head(var_numeric)
var_numeric$X=NULL
```

```{r}
# Matrice di correlazione
R<-cor(var_numeric)            
R
# Test di correlazione. (Spearsman's o Kendall tau)
cor.test(var_numeric$Inches, var_numeric$Weight)
#corrgram(var_numeric)

# Correlazione come grafo
library(qgraph)
detcor=cor(as.matrix(var_numeric), method="pearson")
round(detcor, 2)
# plot corr matrix: green positive red negative 
qgraph(detcor, shape="circle", posCol="darkgreen", negCol="darkred")

```

Boxplot di confronto (pre-anova)
```{r}
boxplot(data$Price~data$Company, 
        main="Boxplot Prezzo per compagnia", 
        col= rainbow(6), 
        horizontal = F)
boxplot(data$Price~data$SolidStateDisk, 
        main="Prezzo vs ssd", 
        col= rainbow(2), 
        horizontal = F)
```

ANOVA

A una via

```{r}
lmA = lm(Price ~ SolidStateDisk, data=data)
summary(lmA)
drop1(lmA, test = 'F')
anova(lmA)

library(lsmeans)
ls_SolidStateDisk = lsmeans(lmA,pairwise ~ SolidStateDisk,adjust = 'tukey')
ls_SolidStateDisk$contrasts 
ls_SolidStateDisk$lsmeans
plot(ls_SolidStateDisk$lsmeans, alpha = .05)
```

```{r}
lmB = lm(Price ~ Company, data=data)
summary(lmB)
drop1(lmB, test = 'F')
anova(lmB)

ls_Company = lsmeans(lmB,pairwise ~ Company,adjust = 'tukey')
ls_Company$contrasts 
ls_Company$lsmeans
plot(ls_Company$lsmeans, alpha = .05)
```

```{r}
lmC = lm(Price ~ TypeName, data=data)
summary(lmC)
drop1(lmC, test = 'F')
anova(lmC)

ls_TypeName = lsmeans(lmC,pairwise ~ TypeName,adjust = 'tukey')
ls_TypeName$contrasts 
ls_TypeName$lsmeans
plot(ls_TypeName$lsmeans, alpha = .05)


library(coefplot)
#library(forestmodel)
coefplot(lmC, intercept = FALSE)

par(mfrow = c(2,2))
plot(lmC)

#(not) normal distribution of residuals
par(mfrow=c(1,2))
boxplot(lmC$residuals)
qqnorm(lmC$residuals);qqline(lmC$residuals)

ad.test(lmC$residuals)
shapiro.test(lmC$residuals)

#let's try again with the log correction
lmC_log = lm(log(Price) ~ TypeName, data=data)
summary(lmC_log)#R^2 increases
drop1(lmC_log, test = 'F')
anova(lmC_log)

ls_TypeName_log = lsmeans(lmC_log,pairwise ~ TypeName,adjust = 'tukey')
ls_TypeName_log$contrasts 
ls_TypeName_log$lsmeans
plot(ls_TypeName_log$lsmeans, alpha = .05)


coefplot(lmC_log, intercept = FALSE)

par(mfrow = c(2,2))
plot(lmC_log)

#(not) normal distribution of residuals
par(mfrow=c(1,2))
boxplot(lmC_log$residuals)
qqnorm(lmC_log$residuals);qqline(lmC_log$residuals)

ad.test(lmC_log$residuals) #normal now!
shapiro.test(lmC_log$residuals) #borderline now!
```


A due vie
```{r}
# Con interazione
lmC = lm(Price ~ Company*TypeName  , data=data)
drop1(lmC, test="F")
summary(lmC)

lmC = lm(Price ~ Company+TypeName  , data=data)
# type I effects A, B/A   C/A,B  
anova(lmC)
# type III effects A/B,C , B/A,C   C/A,B
drop1(lmC, test="F")
summary(lmC)

# contrasti
library(lsmeans)
ls=lsmeans(lmB,
           pairwise ~ TypeName ,
           adjust="tukey")
ls$lsmeans
# plot lsmeans and 95% confid int
plot(ls$lsmeans, alpha = .05)
# contrasts between predicted lsmeans
ls$contrasts
# if at least one contrast is significant, the variable
# is significant in the anova table # drop1 effects

# contrast among predicted lsmeans and overall lsmean
c= contrast(ls, method = "eff")
c
library(coefplot)
coefplot(lmB, intercept=FALSE)
```
ANOVA k way 
```{r}
lmK = lm(Price ~ Company+TypeName+SolidStateDisk  , data=data)
summary(lmK)
drop1(lmK, test="F") # type III SS
coefplot(lmK, intercept=FALSE)
```

Regressione lineare
```{r}
lmA<-lm(Price ~ Frequenza  , data=data)
summary(lmA)
plot(data$Frequenza,data$Price)
abline(lmA,col="red")

lmA<-lm(Price ~ Frequenza+Pixel+Ram  , data=data)
summary(lmA)
coefplot(lmA, intercept=FALSE)

```
ANCOVA

```{r}
lmK = lm(Price ~ Company+TypeName+SolidStateDisk+ Frequenza+Pixel+Ram  , data=data)
summary(lmK)
drop1(lmK, .~., test="F")

ls=lsmeans(lmK,
           pairwise ~ Company ,
           adjust="tukey")
c= contrast(ls, method = "eff")
c
```

```{r}
lm_full = lm(Price ~ ., data = data)
summary(lm_full)
anova(lm_full, test="F")
drop1(lm_full, test="F")

#coefplot(lm_full, intercept=FALSE) #meglio di no ahah

par(mfrow=c(2,2))
plot(lm_full)

par(mfrow=c(1,1))
par(mfrow=c(1,2))
boxplot(lm_full$residuals)
qqnorm(lm_full$residuals);qqline(lm_full$residuals) # probably the correction would work pretty fine here
```

```{r}
#tests
ad.test(lm_full$residuals)
shapiro.test(lm_full$residuals)
```

```{r}
library(MASS)
boxcoxreg1<-boxcox(lm_full)
which.max(boxcoxreg1$y)

lambda=boxcoxreg1$x[which.max(boxcoxreg1$y)]
lambda

lm_full_t = lm(log(Price) ~ ., data = data)

par(mfrow=c(2,2))
plot(lm_full_t) #quite better

ad.test(lm_full_t$residuals) #not really
shapiro.test(lm_full_t$residuals)  #not really
```

A look over outliers

```{r}
library(car)
influencePlot(lm_full,main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )

#Cook's Distance
cooksd <- cooks.distance(lm_full_t)
cooksda=data.frame(cooksd)
summary(cooksd)

# identify D values > 4/(n-k-1)
# Cook's D plot
cutoff <- 4/((nrow(data)-length(lm_full_t$coefficients)-2))
plot(lm_full_t, which=4, cook.levels=cutoff)


plot(cooksd, pch="*", cex=1, main="Influential Obs by Cooks distance") # plot cook's distance
abline(h = cutoff, col="red") # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""),
col="red")#add labels

#extract influencial obs
influential <- as.numeric(names(cooksd)[(cooksd > cutoff)]) # influential row numbers
influ=data.frame(data[cooksd > cutoff, ])
filtered_data <- data[ !(row.names(data) %in% c(influential)), ]
#Outlier rimossi
lm_full_t_no_OUTliers = lm(log(Price) ~ ., data = filtered_data)
par(mfrow=c(2,2))
plot(lm_full_t_no_OUTliers)

summary(lm_full_t_no_OUTliers) #interessante R^2=1, levare un po' di roba se no Lovaglio ci uccide
ncvTest(lm_full_t_no_OUTliers)
```
```{r}
null = lm(log(Price) ~ 1, data = filtered_data)
full = lm(log(Price) ~ ., data = filtered_data)
lm_fit = stepAIC(null, scope = list(upper = full), direction = "both", trace = FALSE)
drop1(lm_fit, test = 'F')
```

