bins= 25,
fill = "grey",
color ="black") +
geom_vline(xintercept = quantile(data$LogPrice, 0.50), color = "dark red", lty = 2) +
geom_vline(xintercept = mean(data$LogPrice), color = "dark blue", lty = 2) +
labs(x = "log(Price)", y ="Density") +
ggtitle("log(Price) Distribution with mean and median")+  geom_density()
data$LogPrice=log(data$Price)
ggplot(data,aes(x = log(Price))) +
geom_histogram(aes(y =..density..),
bins= 25,
fill = "grey",
color ="black") +
geom_vline(xintercept = quantile(data$LogPrice, 0.50), color = "dark red", lty = 2) +
geom_vline(xintercept = mean(data$LogPrice), color = "dark blue", lty = 2) +
labs(x = "log(Price)", y ="Density") +
ggtitle("log(Price) Distribution with mean and median")+  geom_density()
library(ggplot2)
ggplot(data,aes(x = Price)) +
geom_histogram(aes(y =..density..),
bins= 25,
fill = "grey",
color ="black") +
geom_vline(xintercept = quantile(data$Price, 0.50), color = "dark red", lty = 2) +
geom_vline(xintercept = mean(data$Price), color = "dark blue", lty = 2) +
labs(x = "Price", y ="Density") +
ggtitle("Price Distribution with mean and median") +
geom_density()
Quite skewed to the right, mean > median
We could try to apply a correction like Log(Y)
```{r}
data$LogPrice=log(data$Price)
ggplot(data,aes(x = log(Price))) +
geom_histogram(aes(y =..density..),
bins= 25,
fill = "grey",
color ="black") +
geom_vline(xintercept = quantile(data$LogPrice, 0.50), color = "dark red", lty = 2) +
geom_vline(xintercept = mean(data$LogPrice), color = "dark blue", lty = 2) +
labs(x = "log(Price)", y ="Density") +
ggtitle("log(Price) Distribution with mean and median")+  geom_density()
head(var_numeric)
# seleziona solo variabili quantitative
nums <- sapply(data, is.numeric)
var_numeric <- data[,nums]
head(var_numeric)
var_numeric$LogPrice=NULL
# seleziona solo variabili quantitative
nums <- sapply(data, is.numeric)
var_numeric <- data[,nums]
head(var_numeric)
var_numeric$X=NULL
var_numeric$LogPrice=NULL
```{r}
# Matrice di correlazione
R<-cor(var_numeric)
R
# Test di correlazione. (Spearsman's o Kendall tau)
cor.test(var_numeric$Inches, var_numeric$Weight)
# Correlazione come grafo
library(qgraph)
detcor=cor(as.matrix(var_numeric), method="pearson")
round(detcor, 2)
# plot corr matrix: green positive red negative
qgraph(detcor, shape="circle", posCol="darkgreen", negCol="darkred")
boxplot(data$Price~data$Aggregated_Company,
main="Boxplot Prezzo per compagnia",
col= rainbow(6),
horizontal = F)
boxplot(data$LogPrice~data$SolidStateDisk,
main="Prezzo vs ssd",
col= rainbow(2),
horizontal = F)
boxplot(data$LogPrice~data$Aggregated_Company,
main="Boxplot Prezzo per compagnia",
col= rainbow(6),
horizontal = F)
boxplot(data$LogPrice~data$SolidStateDisk,
main="Prezzo vs ssd",
col= rainbow(2),
horizontal = F)
lmA = lm(Price ~ SolidStateDisk, data=data)
summary(lmA)
drop1(lmA, test = 'F')
anova(lmA)
library(lsmeans)
ls_SolidStateDisk = lsmeans(lmA,pairwise ~ SolidStateDisk,adjust = 'tukey')
ls_SolidStateDisk$contrasts
ls_SolidStateDisk$lsmeans
plot(ls_SolidStateDisk$lsmeans, alpha = .05)
ls_SolidStateDisk$contrasts
lmA = lm(LogPrice ~ SolidStateDisk, data=data)
summary(lmA)
drop1(lmA, test = 'F')
anova(lmA)
library(lsmeans)
ls_SolidStateDisk = lsmeans(lmA,pairwise ~ SolidStateDisk,adjust = 'tukey')
ls_SolidStateDisk$contrasts
ls_SolidStateDisk$lsmeans
plot(ls_SolidStateDisk$lsmeans, alpha = .05)
#FIXME: non ricordo se tenere o nop
lmB_agg = lm(Price ~ Aggregated_Company, data=data) #seems to be fine
#FIXME: non ricordo se tenere o nop
lmB_agg = lm(LogPrice ~ Aggregated_Company, data=data) #seems to be fine
summary(lmB_agg)
drop1(lmB_agg, test = 'F')
anova(lmB_agg)
summary(lmB_agg)
ls_Company_agg = lsmeans(lmB_agg,pairwise ~ Aggregated_Company,adjust = 'tukey')
#ls_Company_agg$contrasts #FIXME: too long to be printed
#ls_Company_agg$lsmeans #mFIXME: aybe only the plot is enough?
plot(ls_Company_agg$lsmeans, alpha = .05) #i guess from here seems fine to leave "Razer" alone?
lmC = lm(Price ~ TypeName, data=data)
summary(lmC)
drop1(lmC, test = 'F')
anova(lmC)
ls_TypeName = lsmeans(lmC,pairwise ~ TypeName,adjust = 'tukey')
ls_TypeName$contrasts
ls_TypeName$lsmeans
plot(ls_TypeName$lsmeans, alpha = .05)
library(coefplot)
#library(forestmodel)
coefplot(lmC, intercept = FALSE)
par(mfrow = c(2,2))
plot(lmC)
#(not) normal distribution of residuals
par(mfrow=c(1,2))
boxplot(lmC$residuals)
qqnorm(lmC$residuals);qqline(lmC$residuals)
ad.test(lmC$residuals)
shapiro.test(lmC$residuals)
#let's try again with the log correction
lmC_log = lm(log(Price) ~ TypeName, data=data)
summary(lmC_log)#R^2 increases
drop1(lmC_log, test = 'F')
anova(lmC_log)
ls_TypeName_log = lsmeans(lmC_log,pairwise ~ TypeName,adjust = 'tukey')
ls_TypeName_log$contrasts
ls_TypeName_log$lsmeans
plot(ls_TypeName_log$lsmeans, alpha = .05)
coefplot(lmC_log, intercept = FALSE)
par(mfrow = c(2,2))
plot(lmC_log)
#let's try again with the log correction
lmC_log = lm(LogPrice ~ TypeName, data=data)
summary(lmC_log)#R^2 increases
drop1(lmC_log, test = 'F')
anova(lmC_log)
ls_TypeName_log = lsmeans(lmC_log,pairwise ~ TypeName,adjust = 'tukey')
ls_TypeName_log$contrasts
ls_TypeName_log$lsmeans
plot(ls_TypeName_log$lsmeans, alpha = .05)
coefplot(lmC_log, intercept = FALSE)
coefplot(lmC_log, intercept = FALSE)
plot(ls_TypeName_log$lsmeans, alpha = .05)
coefplot(lmC_log, intercept = FALSE)
par(mfrow = c(2,2))
plot(lmC_log)
#(not) normal distribution of residuals
par(mfrow=c(1,2))
boxplot(lmC_log$residuals)
boxplot(lmC_log$residuals, ylab="residuals (logPrice ~ Typename)")
boxplot(lmC$residuals ylab="residuals (Price ~ Typename)")
boxplot(lmC$residuals, ylab="residuals (Price ~ Typename)")
lmC = lm(Price ~ Company+TypeName  , data=data)
# type I effects A, B/A   C/A,B
anova(lmC)
lmC = lm(LogPrice ~ Aggregated_Company+TypeName  , data=data)
# type I effects A, B/A   C/A,B
anova(lmC)
# type III effects A/B,C , B/A,C   C/A,B
drop1(lmC, test="F")
summary(lmC)
# type I effects A, B/A   C/A,B
anova(lmC)
# type III effects A/B,C , B/A,C   C/A,B
drop1(lmC, test="F")
ls=lsmeans(lmC,
pairwise ~ TypeName ,
adjust="tukey")
ls$lsmeans
# plot lsmeans and 95% confid int
plot(ls$lsmeans, alpha = .05)
# contrasts between predicted lsmeans
ls$contrasts
# contrast among predicted lsmeans and overall lsmean
c= contrast(ls, method = "eff")
c
coefplot(lmC, intercept=FALSE)
# contrast among predicted lsmeans and overall lsmean
c= contrast(ls, method = "eff")
c
library(coefplot)
coefplot(lmC, intercept=FALSE)
lmK = lm(Price ~ Company+TypeName+SolidStateDisk  , data=data)
summary(lmK)
lmK = lm(LogPrice ~ Aggregated_Company+TypeName+SolidStateDisk  , data=data)
summary(lmK)
lmA<-lm(Price ~ Frequenza  , data=data)
lmA<-lm(Price ~ Frequenza  , data=data)
summary(lmA)
plot(data$Frequenza,data$Price)
abline(lmA,col="red")
plot(data$Frequenza,data$Price)
abline(lmA,col="red")
lmA<-lm(Price ~ Frequenza+Pixel+Ram  , data=data)
summary(lmA)
lmA<-lm(LogPrice ~ Frequenza  , data=data)
summary(lmA)
plot(data$Frequenza,data$LogPrice)
uenza,data$LogPrice)
plot(data$Frequenza,data$LogPrice)
abline(lmA,col="red")
lmA<-lm(LogPrice ~ Frequenza+Pixel+Ram  , data=data)
summary(lmA)
coefplot(lmA, intercept=FALSE)
lmK = lm(Price ~ Company+TypeName+SolidStateDisk+ Frequenza+Pixel+Ram  , data=data)
summary(lmK)
drop1(lmK, .~., test="F")
ls=lsmeans(lmK,
pairwise ~ Company ,
adjust="tukey")
c= contrast(ls, method = "eff")
c #FIXME: too long to be printed
Aggregated_Company
lmK = lm(LogPrice ~ Aggregated_Company+TypeName+SolidStateDisk+ Frequenza+Pixel+Ram  , data=data)
summary(lmK)
drop1(lmK, .~., test="F")
ls=lsmeans(lmK,
pairwise ~ Company ,
adjust="tukey")
ls=lsmeans(lmK,
pairwise ~ Aggregated_Company ,
adjust="tukey")
c= contrast(ls, method = "eff")
c #FIXME: too long to be printed
data$LogPrice=NULL
data$Product=NULL
data$X=NULL
lm_full = lm(log(Price) ~ ., data = data)
#summary(lm_full) #FIXME: wayyy too long to be printed, R^2 =0.9586
anova(lm_full, test="F")
drop1(lm_full, test="F")
drop1(lm_full, test="F")
par(mfrow=c(2,2))
plot(lm_full)
par(mfrow=c(1,1))
par(mfrow=c(1,1))
par(mfrow=c(1,2))
boxplot(lm_full$residuals)
qqnorm(lm_full$residuals);qqline(lm_full$residuals) # probably the correction would work pretty fine here
boxplot(lm_full$residuals, ylab="residuals (log(Price) ~ .")
boxplot(lm_full$residuals, ylab="residuals (log(Price) ~ .)")
qqnorm(lm_full$residuals);qqline(lm_full$residuals) # probably the correction would work pretty fine here
#tests
ad.test(lm_full$residuals)
shapiro.test(lm_full$residuals)
#tests
ad.test(lm_full$residuals)
lm_full = lm(log(Price) ~ ., data = data)
#summary(lm_full) #FIXME: wayyy too long to be printed, R^2 =0.9586
anova(lm_full, test="F")
drop1(lm_full, test="F")
drop1(lm_full, test="F")
par(mfrow=c(2,2))
plot(lm_full)
plot(lm_full)
par(mfrow=c(1,1))
par(mfrow=c(2,2))
plot(lm_full)
par(mfrow=c(1,1))
par(mfrow=c(1,2))
boxplot(lm_full$residuals, ylab="residuals (log(Price) ~ .)")
qqnorm(lm_full$residuals);qqline(lm_full$residuals) # probably the correction would work pretty fine here
par(mfrow=c(1,1))
par(mfrow=c(1,2))
boxplot(lm_full$residuals, ylab="residuals (log(Price) ~ .)")
qqnorm(lm_full$residuals);qqline(lm_full$residuals) # probably the correction would work pretty fine here
```{r}
#tests
ad.test(lm_full$residuals)
shapiro.test(lm_full$residuals)
#tests
ad.test(lm_full$residuals)
shapiro.test(lm_full$residuals)
influencePlot(lm_full,main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )
library(car)
influencePlot(lm_full,main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )
data$Company=NULL
str(data)
data$Gpu
data$Gpu=NULL
str(data)
data$LogPrice=NULL
data$X=NULL
data$Company=NULL
data$Gpu=NULL
data$ScreenResolution=NULL
data$Risoluzione=NULL
str(data)
lm_full = lm(log(Price) ~ ., data = data)
summary(lm_full) #FIXME: wayyy too long to be printed, R^2 =0.9586
data$Cpu=NULL #uso solo Frequenza
str(data)
lm_full = lm(log(Price) ~ ., data = data)
summary(lm_full) #FIXME: wayyy too long to be printed, R^2 =0.9586
anova(lm_full, test="F")
drop1(lm_full, test="F")
summary(lm_full) #FIXME: wayyy too long to be printed, R^2 =0.9586
data$Memory
data$Memory=NULL #uso solo MemorySSD e SolidStateDisk
str(data)
data$Memory=NULL #uso solo MemorySSD, TotalMemory e SolidStateDisk
str(data)
lm_full = lm(log(Price) ~ ., data = data)
summary(lm_full) #FIXME: wayyy too long to be printed, R^2 =0.9586
summary(lm_full)
lmK = lm(LogPrice ~ Aggregated_Company+TypeName+SolidStateDisk+ Frequenza+Pixel+Ram  , data=data)
summary(lmK)
lmK = lm(LogPrice ~ Aggregated_Company+TypeName+SolidStateDisk+ Frequenza+Pixel+Ram  , data=data)
summary(lmK)
lmK = lm(LogPrice ~ Aggregated_Company+TypeName+SolidStateDisk+ Frequenza+Pixel+Ram  , data=data)
lmK = lm(log(Price) ~ Aggregated_Company+TypeName+SolidStateDisk+ Frequenza+Pixel+Ram  , data=data)
summary(lmK)
#tests
ad.test(lm_full$residuals)
shapiro.test(lm_full$residuals)
coefplot(lm_full, intercept=FALSE) #meglio di no ahah
qqnorm(lm_full$residuals);qqline(lm_full$residuals)
boxplot(lm_full$residuals, ylab="residuals (log(Price) ~ .)")
library(car)
influencePlot(lm_full,main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )
data$LogPrice=NULL
data$Product=NULL
data$Company=NULL #uso solo Aggregated_Company
data$Gpu=NULL #uso solo Gpu_company e dedicated_GPU
data$Risoluzione=NULL #uso solo Pixels
data$Cpu=NULL #uso solo Frequenza
data$Memory=NULL #uso solo MemorySSD, TotalMemory e SolidStateDisk
str(data)
lm_full = lm(log(Price) ~ ., data = data)
summary(lm_full)
anova(lm_full, test="F")
drop1(lm_full, test="F")
coefplot(lm_full, intercept=FALSE)
par(mfrow=c(2,2))
plot(lm_full)
par(mfrow=c(1,1))
par(mfrow=c(1,2))
boxplot(lm_full$residuals, ylab="residuals (log(Price) ~ .)")
qqnorm(lm_full$residuals);qqline(lm_full$residuals)
par(mfrow=c(1,1))
par(mfrow=c(1,2))
boxplot(lm_full$residuals, ylab="residuals (log(Price) ~ .)")
qqnorm(lm_full$residuals);qqline(lm_full$residuals)
```{r}
#tests
ad.test(lm_full$residuals)
shapiro.test(lm_full$residuals)
#tests
ad.test(lm_full$residuals)
shapiro.test(lm_full$residuals)
#tests
ad.test(lm_full$residuals)
shapiro.test(lm_full$residuals)
A look over outliers
```{r, fig.height=4, fig.width=6}
library(car)
influencePlot(lm_full,main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )
#Cook's Distance
cooksd <- cooks.distance(lm_full_t)
#Cook's Distance
cooksd <- cooks.distance(lm_full_t)
cooksda=data.frame(cooksd)
#Cook's Distance
cooksd <- cooks.distance(lm_full_t)
cooksda=data.frame(cooksd)
summary(cooksd)
influencePlot(lm_full,main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )
#Cook's Distance
cooksd <- cooks.distance(lm_full_t)
# identify D values > 4/(n-k-1)
# Cook's D plot
cutoff <- 4/((nrow(data)-length(lm_full_t$coefficients)-2))
plot(lm_full_t, which=4, cook.levels=cutoff)
plot(cooksd, pch="*", cex=1, main="Influential Obs by Cooks distance") # plot cook's distance
plot(cooksd, pch="*", cex=1, main="Influential Obs by Cooks distance") # plot cook's distance
abline(h = cutoff, col="red") # add cutoff line
plot(cooksd, pch="*", cex=1, main="Influential Obs by Cooks distance") # plot cook's distance
abline(h = cutoff, col="red") # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""),
col="red")#add labels
#extract influencial obs
influential <- as.numeric(names(cooksd)[(cooksd > cutoff)]) # influential row numbers
influ=data.frame(data[cooksd > cutoff, ])
filtered_data <- data[ !(row.names(data) %in% c(influential)), ]
#Outlier rimossi
lm_full_t_no_OUTliers = lm(log(Price) ~ ., data = filtered_data)
summary(lm_full_t_no_OUTliers)
#summary(lm_full_t_no_OUTliers) #FIXME: too long to be printed, R^2=0.9727
ncvTest(lm_full_t_no_OUTliers)
null = lm(log(Price) ~ 1, data = filtered_data)
full = lm(log(Price) ~ ., data = filtered_data)
lm_fit = stepAIC(null, scope = list(upper = full), direction = "both", trace = FALSE)
library(MASS)
lm_fit = stepAIC(null, scope = list(upper = full), direction = "both", trace = FALSE)
drop1(lm_fit, test = 'F')
summary(lm_fit)
lm_full_t = lm(Price ~ ., data = data)
summary(lm_full)
summary(lm_full_no_log)
lm_full_no_log = lm(Price ~ ., data = data)
summary(lm_full_no_log)
par(mfrow=c(2,2))
#to justify log correction
boxcoxreg1<-boxcox(lm_full, plotit=T)
which.max(boxcoxreg1$y)
lambda=boxcoxreg1$x[which.max(boxcoxreg1$y)]
lambda #FIXME: not really 0, one should actually apply (((y  )^lambda) - 1) / lambda but meh
#Cook's Distance
cooksd <- cooks.distance(lm_full)
cooksda=data.frame(cooksd)
summary(cooksd)
# identify D values > 4/(n-k-1)
# Cook's D plot
cutoff <- 4/((nrow(data)-length(lm_full_t$coefficients)-2))
plot(lm_full_t, which=4, cook.levels=cutoff)
plot(lm_full, which=4, cook.levels=cutoff)
plot(cooksd, pch="*", cex=1, main="Influential Obs by Cooks distance") # plot cook's distance
abline(h = cutoff, col="red") # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""),
col="red")#add labels
#extract influencial obs
influential <- as.numeric(names(cooksd)[(cooksd > cutoff)]) # influential row numbers
influ=data.frame(data[cooksd > cutoff, ])
filtered_data <- data[ !(row.names(data) %in% c(influential)), ]
#Outlier rimossi
lm_full_t_no_OUTliers = lm(log(Price) ~ ., data = filtered_data)
summary(lm_full_t_no_OUTliers)
par(mfrow=c(2,2))
plot(lm_full_t_no_OUTliers)
summary(lm_full_t_no_OUTliers)
data$dedicated_GPU=NULL
# identify D values > 4/(n-k-1)
# Cook's D plot
cutoff <- 4/((nrow(data)-length(lm_full$coefficients)-2))
plot(lm_full, which=4, cook.levels=cutoff)
plot(cooksd, pch="*", cex=1, main="Influential Obs by Cooks distance") # plot cook's distance
abline(h = cutoff, col="red") # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""),
col="red")#add labels
corrgram(var_numeric)
# Matrice di correlazione
R<-cor(var_numeric)
R
# Test di correlazione. (Spearsman's o Kendall tau)
cor.test(var_numeric$Inches, var_numeric$Weight)
corrgram(var_numeric)
corrgram(var_numeric)
library(corrgram)
if(!require(corrgram)) install.packages("corrgram")
library(corrgram)
corrgram(var_numeric)
corrgram(var_numeric, cor.method = "spearsman")
corrgram(var_numeric, cor.method = "spearman")
corrgram(var_numeric, cor.method = "pearson")
corrgram(var_numeric, ccor.method = "kendall")
detcor=cor(as.matrix(var_numeric))
corrgram(var_numeric)
ls_Company_agg$contrasts
#FIXME: tolto Price vs Aggregated_company, non ricordo se tenere o nop
#extract influencial obs
influential <- as.numeric(names(cooksd)[(cooksd > cutoff)]) # influential row numbers
influ=data.frame(data[cooksd > cutoff, ])
dim(influ)
dim(data)
dim(filtered_data)
cat(dim(influ), dim(data), dim(filtered_data))
dim(influ), dim(data), dim(filtered_data)
dim(influ) dim(data) dim(filtered_data)
dim(influ); dim(data); dim(filtered_data)
#Outlier rimossi
lm_full_t_no_OUTliers = lm(log(Price) ~ ., data = filtered_data)
summary(lm_full_t_no_OUTliers)
par(mfrow=c(2,2))
plot(lm_full_t_no_OUTliers)
null = lm(log(Price) ~ 1, data = filtered_data)
full = lm(log(Price) ~ ., data = filtered_data)
library(MASS)
lm_fit = stepAIC(null, scope = list(upper = full), direction = "both", trace = FALSE)
summary(lm_fit)
drop1(lm_fit, test = 'F')
\Small
```{r}
summary(lmK)
```
\normalsize
head(var_numeric, 2)
round(R, 2)
```{r}
boxplot(data$LogPrice~data$Aggregated_Company, main="Boxplot Prezzo per compagnia", col= rainbow(6), horizontal = F)
boxplot(log(data$Price)~data$Aggregated_Company, main="Boxplot Prezzo per compagnia", col= rainbow(6), horizontal = F)
boxplot(data$LogPrice~data$SolidStateDisk, main="Prezzo vs ssd", col= rainbow(2), horizontal = F)
pander(summary(data))
library(pander)
pander(summary(data))
pander(summary(data), caption = F)
pander(summary(data), caption = F)
pander(summary(data), caption ="")
pander(str(data))
pander(summary(data), split.table="inf", caption ="")
library(pander)
